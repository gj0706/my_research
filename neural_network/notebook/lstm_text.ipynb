{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Embedding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_weight_file(file_path):\n",
    "    f = h5py.File(file_path,'r')\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['output1', 'states1']>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = read_weight_file('../../../LSTMVis/data/05childbook/05childbook/states.h5')\n",
    "f.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"states1\": shape (1271900, 200), type \"<f4\">"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['states1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<HDF5 dataset \"output1\": shape (1271900, 200), type \"<f4\">"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f['output1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.999395</td>\n",
       "      <td>0.139939</td>\n",
       "      <td>-0.133315</td>\n",
       "      <td>-0.707135</td>\n",
       "      <td>0.092862</td>\n",
       "      <td>-0.653351</td>\n",
       "      <td>-0.812206</td>\n",
       "      <td>-0.873559</td>\n",
       "      <td>0.677905</td>\n",
       "      <td>0.112582</td>\n",
       "      <td>...</td>\n",
       "      <td>0.168090</td>\n",
       "      <td>0.058637</td>\n",
       "      <td>0.138943</td>\n",
       "      <td>-0.447951</td>\n",
       "      <td>0.771288</td>\n",
       "      <td>-0.997505</td>\n",
       "      <td>-0.792947</td>\n",
       "      <td>0.015164</td>\n",
       "      <td>-0.005032</td>\n",
       "      <td>-0.679110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.079009</td>\n",
       "      <td>0.534143</td>\n",
       "      <td>0.827991</td>\n",
       "      <td>-0.070337</td>\n",
       "      <td>0.105284</td>\n",
       "      <td>0.412934</td>\n",
       "      <td>-1.022239</td>\n",
       "      <td>-0.830880</td>\n",
       "      <td>-0.026431</td>\n",
       "      <td>-0.006075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019834</td>\n",
       "      <td>0.996436</td>\n",
       "      <td>0.041451</td>\n",
       "      <td>0.081331</td>\n",
       "      <td>0.156615</td>\n",
       "      <td>0.748737</td>\n",
       "      <td>-0.289053</td>\n",
       "      <td>-0.032697</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.674544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.913969</td>\n",
       "      <td>0.486170</td>\n",
       "      <td>0.108466</td>\n",
       "      <td>-0.306623</td>\n",
       "      <td>0.690331</td>\n",
       "      <td>0.952605</td>\n",
       "      <td>-0.343406</td>\n",
       "      <td>0.370140</td>\n",
       "      <td>-0.376919</td>\n",
       "      <td>0.525713</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066910</td>\n",
       "      <td>0.591809</td>\n",
       "      <td>0.896092</td>\n",
       "      <td>0.371651</td>\n",
       "      <td>-0.720150</td>\n",
       "      <td>0.428870</td>\n",
       "      <td>-0.842386</td>\n",
       "      <td>-0.042881</td>\n",
       "      <td>-0.099725</td>\n",
       "      <td>-0.727310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.456632</td>\n",
       "      <td>-0.896531</td>\n",
       "      <td>0.167117</td>\n",
       "      <td>0.408090</td>\n",
       "      <td>0.914130</td>\n",
       "      <td>0.024740</td>\n",
       "      <td>0.794913</td>\n",
       "      <td>-0.578901</td>\n",
       "      <td>-0.324473</td>\n",
       "      <td>0.224386</td>\n",
       "      <td>...</td>\n",
       "      <td>0.273680</td>\n",
       "      <td>0.825968</td>\n",
       "      <td>-0.203984</td>\n",
       "      <td>0.026162</td>\n",
       "      <td>0.940264</td>\n",
       "      <td>0.559527</td>\n",
       "      <td>-0.701537</td>\n",
       "      <td>-0.051908</td>\n",
       "      <td>0.020711</td>\n",
       "      <td>-0.741639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.598989</td>\n",
       "      <td>-1.001568</td>\n",
       "      <td>0.034984</td>\n",
       "      <td>-0.366462</td>\n",
       "      <td>0.935715</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>1.028395</td>\n",
       "      <td>-1.051747</td>\n",
       "      <td>-0.697554</td>\n",
       "      <td>1.023287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390594</td>\n",
       "      <td>0.728473</td>\n",
       "      <td>-0.713890</td>\n",
       "      <td>0.082018</td>\n",
       "      <td>0.979188</td>\n",
       "      <td>0.212284</td>\n",
       "      <td>-1.270396</td>\n",
       "      <td>-0.065537</td>\n",
       "      <td>-0.003914</td>\n",
       "      <td>-0.826838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.999395  0.139939 -0.133315 -0.707135  0.092862 -0.653351 -0.812206   \n",
       "1  0.079009  0.534143  0.827991 -0.070337  0.105284  0.412934 -1.022239   \n",
       "2 -0.913969  0.486170  0.108466 -0.306623  0.690331  0.952605 -0.343406   \n",
       "3 -0.456632 -0.896531  0.167117  0.408090  0.914130  0.024740  0.794913   \n",
       "4 -0.598989 -1.001568  0.034984 -0.366462  0.935715  0.999910  1.028395   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0 -0.873559  0.677905  0.112582  ...  0.168090  0.058637  0.138943 -0.447951   \n",
       "1 -0.830880 -0.026431 -0.006075  ... -0.019834  0.996436  0.041451  0.081331   \n",
       "2  0.370140 -0.376919  0.525713  ...  0.066910  0.591809  0.896092  0.371651   \n",
       "3 -0.578901 -0.324473  0.224386  ...  0.273680  0.825968 -0.203984  0.026162   \n",
       "4 -1.051747 -0.697554  1.023287  ...  0.390594  0.728473 -0.713890  0.082018   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.771288 -0.997505 -0.792947  0.015164 -0.005032 -0.679110  \n",
       "1  0.156615  0.748737 -0.289053 -0.032697  0.000016 -0.674544  \n",
       "2 -0.720150  0.428870 -0.842386 -0.042881 -0.099725 -0.727310  \n",
       "3  0.940264  0.559527 -0.701537 -0.051908  0.020711 -0.741639  \n",
       "4  0.979188  0.212284 -1.270396 -0.065537 -0.003914 -0.826838  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_states = pd.DataFrame(np.array(f['states1']))\n",
    "df_states.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1271900, 200)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.581290</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>-0.027683</td>\n",
       "      <td>-0.430689</td>\n",
       "      <td>0.033046</td>\n",
       "      <td>-0.043899</td>\n",
       "      <td>-0.112473</td>\n",
       "      <td>-0.680815</td>\n",
       "      <td>0.539585</td>\n",
       "      <td>0.006208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.095224</td>\n",
       "      <td>0.056019</td>\n",
       "      <td>0.137070</td>\n",
       "      <td>-0.226631</td>\n",
       "      <td>0.643734</td>\n",
       "      <td>-0.495256</td>\n",
       "      <td>-0.507912</td>\n",
       "      <td>0.009428</td>\n",
       "      <td>-0.001253</td>\n",
       "      <td>-0.321540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.032917</td>\n",
       "      <td>0.008198</td>\n",
       "      <td>0.093196</td>\n",
       "      <td>-0.047473</td>\n",
       "      <td>0.103909</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>-0.094483</td>\n",
       "      <td>-0.680342</td>\n",
       "      <td>-0.026275</td>\n",
       "      <td>-0.001114</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>0.312569</td>\n",
       "      <td>0.041424</td>\n",
       "      <td>0.013392</td>\n",
       "      <td>0.123176</td>\n",
       "      <td>0.043307</td>\n",
       "      <td>-0.259534</td>\n",
       "      <td>-0.032407</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>-0.485580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-0.501529</td>\n",
       "      <td>0.075285</td>\n",
       "      <td>0.036841</td>\n",
       "      <td>-0.226716</td>\n",
       "      <td>0.015573</td>\n",
       "      <td>0.318165</td>\n",
       "      <td>-0.023613</td>\n",
       "      <td>0.349541</td>\n",
       "      <td>-0.229377</td>\n",
       "      <td>0.423139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036713</td>\n",
       "      <td>0.434348</td>\n",
       "      <td>0.628503</td>\n",
       "      <td>0.111479</td>\n",
       "      <td>-0.589384</td>\n",
       "      <td>0.358589</td>\n",
       "      <td>-0.510057</td>\n",
       "      <td>-0.031762</td>\n",
       "      <td>-0.000549</td>\n",
       "      <td>-0.502966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-0.401368</td>\n",
       "      <td>-0.456501</td>\n",
       "      <td>0.006114</td>\n",
       "      <td>0.149163</td>\n",
       "      <td>0.625086</td>\n",
       "      <td>0.021770</td>\n",
       "      <td>0.007484</td>\n",
       "      <td>-0.042390</td>\n",
       "      <td>-0.034800</td>\n",
       "      <td>0.162708</td>\n",
       "      <td>...</td>\n",
       "      <td>0.156461</td>\n",
       "      <td>0.501618</td>\n",
       "      <td>-0.016214</td>\n",
       "      <td>0.018712</td>\n",
       "      <td>0.420728</td>\n",
       "      <td>0.021748</td>\n",
       "      <td>-0.513047</td>\n",
       "      <td>-0.042374</td>\n",
       "      <td>0.019856</td>\n",
       "      <td>-0.559717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-0.251165</td>\n",
       "      <td>-0.067411</td>\n",
       "      <td>0.033815</td>\n",
       "      <td>-0.004376</td>\n",
       "      <td>0.555721</td>\n",
       "      <td>0.070168</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>-0.772693</td>\n",
       "      <td>-0.516666</td>\n",
       "      <td>0.757734</td>\n",
       "      <td>...</td>\n",
       "      <td>0.169819</td>\n",
       "      <td>0.068413</td>\n",
       "      <td>-0.152470</td>\n",
       "      <td>0.065834</td>\n",
       "      <td>0.752220</td>\n",
       "      <td>0.209106</td>\n",
       "      <td>-0.767739</td>\n",
       "      <td>-0.053505</td>\n",
       "      <td>-0.002154</td>\n",
       "      <td>-0.658323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.581290  0.000340 -0.027683 -0.430689  0.033046 -0.043899 -0.112473   \n",
       "1  0.032917  0.008198  0.093196 -0.047473  0.103909  0.000585 -0.094483   \n",
       "2 -0.501529  0.075285  0.036841 -0.226716  0.015573  0.318165 -0.023613   \n",
       "3 -0.401368 -0.456501  0.006114  0.149163  0.625086  0.021770  0.007484   \n",
       "4 -0.251165 -0.067411  0.033815 -0.004376  0.555721  0.070168  0.004318   \n",
       "\n",
       "        7         8         9    ...       190       191       192       193  \\\n",
       "0 -0.680815  0.539585  0.006208  ...  0.095224  0.056019  0.137070 -0.226631   \n",
       "1 -0.680342 -0.026275 -0.001114  ... -0.016411  0.312569  0.041424  0.013392   \n",
       "2  0.349541 -0.229377  0.423139  ...  0.036713  0.434348  0.628503  0.111479   \n",
       "3 -0.042390 -0.034800  0.162708  ...  0.156461  0.501618 -0.016214  0.018712   \n",
       "4 -0.772693 -0.516666  0.757734  ...  0.169819  0.068413 -0.152470  0.065834   \n",
       "\n",
       "        194       195       196       197       198       199  \n",
       "0  0.643734 -0.495256 -0.507912  0.009428 -0.001253 -0.321540  \n",
       "1  0.123176  0.043307 -0.259534 -0.032407  0.000011 -0.485580  \n",
       "2 -0.589384  0.358589 -0.510057 -0.031762 -0.000549 -0.502966  \n",
       "3  0.420728  0.021748 -0.513047 -0.042374  0.019856 -0.559717  \n",
       "4  0.752220  0.209106 -0.767739 -0.053505 -0.002154 -0.658323  \n",
       "\n",
       "[5 rows x 200 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_output = pd.DataFrame(np.array(f['output1']))\n",
    "df_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['indices', 'set_size', 'target', 'target_output', 'target_size', 'words']>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = read_weight_file('../../../LSTMVis/data/05childbook/05childbook/train.h5')\n",
    "s.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      0\n",
       "0  1817\n",
       "1    20\n",
       "2    35"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = s['indices'].shape\n",
    "ind_df = pd.DataFrame(np.array(ind))\n",
    "ind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1271907</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1271908</td>\n",
       "      <td>632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1271909</td>\n",
       "      <td>2680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1271910</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1271911</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1271912 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0           3\n",
       "1           4\n",
       "2           5\n",
       "3           1\n",
       "4           6\n",
       "...       ...\n",
       "1271907   355\n",
       "1271908   632\n",
       "1271909  2680\n",
       "1271910    22\n",
       "1271911     1\n",
       "\n",
       "[1271912 rows x 1 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(np.array(s['words']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 22\n",
      "Total Sequences: 24\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 1, 10)             220       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 50)                12200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 22)                1122      \n",
      "=================================================================\n",
      "Total params: 13,542\n",
      "Trainable params: 13,542\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaywang/anaconda3/envs/data_science/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      " - 1s - loss: 3.0916 - accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      " - 0s - loss: 3.0909 - accuracy: 0.0417\n",
      "Epoch 3/500\n",
      " - 0s - loss: 3.0901 - accuracy: 0.1250\n",
      "Epoch 4/500\n",
      " - 0s - loss: 3.0894 - accuracy: 0.1250\n",
      "Epoch 5/500\n",
      " - 0s - loss: 3.0887 - accuracy: 0.1250\n",
      "Epoch 6/500\n",
      " - 0s - loss: 3.0880 - accuracy: 0.1250\n",
      "Epoch 7/500\n",
      " - 0s - loss: 3.0872 - accuracy: 0.1250\n",
      "Epoch 8/500\n",
      " - 0s - loss: 3.0865 - accuracy: 0.2083\n",
      "Epoch 9/500\n",
      " - 0s - loss: 3.0857 - accuracy: 0.2083\n",
      "Epoch 10/500\n",
      " - 0s - loss: 3.0849 - accuracy: 0.2083\n",
      "Epoch 11/500\n",
      " - 0s - loss: 3.0841 - accuracy: 0.2083\n",
      "Epoch 12/500\n",
      " - 0s - loss: 3.0833 - accuracy: 0.2083\n",
      "Epoch 13/500\n",
      " - 0s - loss: 3.0825 - accuracy: 0.2083\n",
      "Epoch 14/500\n",
      " - 0s - loss: 3.0817 - accuracy: 0.2083\n",
      "Epoch 15/500\n",
      " - 0s - loss: 3.0809 - accuracy: 0.2083\n",
      "Epoch 16/500\n",
      " - 0s - loss: 3.0800 - accuracy: 0.2083\n",
      "Epoch 17/500\n",
      " - 0s - loss: 3.0792 - accuracy: 0.2083\n",
      "Epoch 18/500\n",
      " - 0s - loss: 3.0783 - accuracy: 0.2083\n",
      "Epoch 19/500\n",
      " - 0s - loss: 3.0774 - accuracy: 0.2083\n",
      "Epoch 20/500\n",
      " - 0s - loss: 3.0764 - accuracy: 0.2083\n",
      "Epoch 21/500\n",
      " - 0s - loss: 3.0755 - accuracy: 0.2083\n",
      "Epoch 22/500\n",
      " - 0s - loss: 3.0745 - accuracy: 0.2083\n",
      "Epoch 23/500\n",
      " - 0s - loss: 3.0735 - accuracy: 0.2083\n",
      "Epoch 24/500\n",
      " - 0s - loss: 3.0725 - accuracy: 0.2083\n",
      "Epoch 25/500\n",
      " - 0s - loss: 3.0715 - accuracy: 0.2083\n",
      "Epoch 26/500\n",
      " - 0s - loss: 3.0704 - accuracy: 0.2083\n",
      "Epoch 27/500\n",
      " - 0s - loss: 3.0693 - accuracy: 0.2083\n",
      "Epoch 28/500\n",
      " - 0s - loss: 3.0682 - accuracy: 0.2083\n",
      "Epoch 29/500\n",
      " - 0s - loss: 3.0670 - accuracy: 0.2083\n",
      "Epoch 30/500\n",
      " - 0s - loss: 3.0658 - accuracy: 0.2083\n",
      "Epoch 31/500\n",
      " - 0s - loss: 3.0646 - accuracy: 0.2083\n",
      "Epoch 32/500\n",
      " - 0s - loss: 3.0633 - accuracy: 0.2083\n",
      "Epoch 33/500\n",
      " - 0s - loss: 3.0620 - accuracy: 0.2083\n",
      "Epoch 34/500\n",
      " - 0s - loss: 3.0607 - accuracy: 0.2083\n",
      "Epoch 35/500\n",
      " - 0s - loss: 3.0593 - accuracy: 0.2083\n",
      "Epoch 36/500\n",
      " - 0s - loss: 3.0578 - accuracy: 0.2083\n",
      "Epoch 37/500\n",
      " - 0s - loss: 3.0564 - accuracy: 0.2083\n",
      "Epoch 38/500\n",
      " - 0s - loss: 3.0549 - accuracy: 0.2083\n",
      "Epoch 39/500\n",
      " - 0s - loss: 3.0533 - accuracy: 0.2083\n",
      "Epoch 40/500\n",
      " - 0s - loss: 3.0517 - accuracy: 0.2083\n",
      "Epoch 41/500\n",
      " - 0s - loss: 3.0500 - accuracy: 0.2083\n",
      "Epoch 42/500\n",
      " - 0s - loss: 3.0483 - accuracy: 0.2083\n",
      "Epoch 43/500\n",
      " - 0s - loss: 3.0466 - accuracy: 0.2083\n",
      "Epoch 44/500\n",
      " - 0s - loss: 3.0447 - accuracy: 0.2083\n",
      "Epoch 45/500\n",
      " - 0s - loss: 3.0429 - accuracy: 0.2083\n",
      "Epoch 46/500\n",
      " - 0s - loss: 3.0409 - accuracy: 0.2083\n",
      "Epoch 47/500\n",
      " - 0s - loss: 3.0389 - accuracy: 0.2083\n",
      "Epoch 48/500\n",
      " - 0s - loss: 3.0368 - accuracy: 0.2083\n",
      "Epoch 49/500\n",
      " - 0s - loss: 3.0347 - accuracy: 0.2083\n",
      "Epoch 50/500\n",
      " - 0s - loss: 3.0325 - accuracy: 0.2083\n",
      "Epoch 51/500\n",
      " - 0s - loss: 3.0302 - accuracy: 0.2083\n",
      "Epoch 52/500\n",
      " - 0s - loss: 3.0279 - accuracy: 0.2083\n",
      "Epoch 53/500\n",
      " - 0s - loss: 3.0254 - accuracy: 0.2083\n",
      "Epoch 54/500\n",
      " - 0s - loss: 3.0230 - accuracy: 0.2083\n",
      "Epoch 55/500\n",
      " - 0s - loss: 3.0204 - accuracy: 0.2083\n",
      "Epoch 56/500\n",
      " - 0s - loss: 3.0178 - accuracy: 0.2083\n",
      "Epoch 57/500\n",
      " - 0s - loss: 3.0150 - accuracy: 0.2083\n",
      "Epoch 58/500\n",
      " - 0s - loss: 3.0122 - accuracy: 0.2083\n",
      "Epoch 59/500\n",
      " - 0s - loss: 3.0093 - accuracy: 0.2083\n",
      "Epoch 60/500\n",
      " - 0s - loss: 3.0063 - accuracy: 0.2083\n",
      "Epoch 61/500\n",
      " - 0s - loss: 3.0033 - accuracy: 0.2083\n",
      "Epoch 62/500\n",
      " - 0s - loss: 3.0001 - accuracy: 0.2083\n",
      "Epoch 63/500\n",
      " - 0s - loss: 2.9968 - accuracy: 0.2083\n",
      "Epoch 64/500\n",
      " - 0s - loss: 2.9934 - accuracy: 0.2083\n",
      "Epoch 65/500\n",
      " - 0s - loss: 2.9899 - accuracy: 0.2083\n",
      "Epoch 66/500\n",
      " - 0s - loss: 2.9863 - accuracy: 0.2083\n",
      "Epoch 67/500\n",
      " - 0s - loss: 2.9826 - accuracy: 0.2083\n",
      "Epoch 68/500\n",
      " - 0s - loss: 2.9788 - accuracy: 0.2083\n",
      "Epoch 69/500\n",
      " - 0s - loss: 2.9749 - accuracy: 0.2083\n",
      "Epoch 70/500\n",
      " - 0s - loss: 2.9709 - accuracy: 0.2083\n",
      "Epoch 71/500\n",
      " - 0s - loss: 2.9667 - accuracy: 0.2083\n",
      "Epoch 72/500\n",
      " - 0s - loss: 2.9624 - accuracy: 0.2083\n",
      "Epoch 73/500\n",
      " - 0s - loss: 2.9580 - accuracy: 0.2083\n",
      "Epoch 74/500\n",
      " - 0s - loss: 2.9535 - accuracy: 0.2083\n",
      "Epoch 75/500\n",
      " - 0s - loss: 2.9488 - accuracy: 0.2083\n",
      "Epoch 76/500\n",
      " - 0s - loss: 2.9440 - accuracy: 0.2083\n",
      "Epoch 77/500\n",
      " - 0s - loss: 2.9391 - accuracy: 0.2083\n",
      "Epoch 78/500\n",
      " - 0s - loss: 2.9340 - accuracy: 0.2083\n",
      "Epoch 79/500\n",
      " - 0s - loss: 2.9288 - accuracy: 0.2083\n",
      "Epoch 80/500\n",
      " - 0s - loss: 2.9234 - accuracy: 0.2083\n",
      "Epoch 81/500\n",
      " - 0s - loss: 2.9179 - accuracy: 0.2083\n",
      "Epoch 82/500\n",
      " - 0s - loss: 2.9123 - accuracy: 0.2083\n",
      "Epoch 83/500\n",
      " - 0s - loss: 2.9065 - accuracy: 0.2083\n",
      "Epoch 84/500\n",
      " - 0s - loss: 2.9005 - accuracy: 0.2083\n",
      "Epoch 85/500\n",
      " - 0s - loss: 2.8943 - accuracy: 0.2083\n",
      "Epoch 86/500\n",
      " - 0s - loss: 2.8880 - accuracy: 0.2083\n",
      "Epoch 87/500\n",
      " - 0s - loss: 2.8815 - accuracy: 0.2083\n",
      "Epoch 88/500\n",
      " - 0s - loss: 2.8749 - accuracy: 0.2083\n",
      "Epoch 89/500\n",
      " - 0s - loss: 2.8680 - accuracy: 0.2083\n",
      "Epoch 90/500\n",
      " - 0s - loss: 2.8610 - accuracy: 0.2083\n",
      "Epoch 91/500\n",
      " - 0s - loss: 2.8538 - accuracy: 0.2083\n",
      "Epoch 92/500\n",
      " - 0s - loss: 2.8465 - accuracy: 0.2083\n",
      "Epoch 93/500\n",
      " - 0s - loss: 2.8390 - accuracy: 0.2083\n",
      "Epoch 94/500\n",
      " - 0s - loss: 2.8313 - accuracy: 0.2083\n",
      "Epoch 95/500\n",
      " - 0s - loss: 2.8235 - accuracy: 0.2083\n",
      "Epoch 96/500\n",
      " - 0s - loss: 2.8154 - accuracy: 0.2083\n",
      "Epoch 97/500\n",
      " - 0s - loss: 2.8072 - accuracy: 0.2083\n",
      "Epoch 98/500\n",
      " - 0s - loss: 2.7988 - accuracy: 0.2083\n",
      "Epoch 99/500\n",
      " - 0s - loss: 2.7902 - accuracy: 0.2083\n",
      "Epoch 100/500\n",
      " - 0s - loss: 2.7814 - accuracy: 0.2083\n",
      "Epoch 101/500\n",
      " - 0s - loss: 2.7725 - accuracy: 0.2083\n",
      "Epoch 102/500\n",
      " - 0s - loss: 2.7634 - accuracy: 0.2083\n",
      "Epoch 103/500\n",
      " - 0s - loss: 2.7541 - accuracy: 0.2083\n",
      "Epoch 104/500\n",
      " - 0s - loss: 2.7446 - accuracy: 0.2083\n",
      "Epoch 105/500\n",
      " - 0s - loss: 2.7349 - accuracy: 0.2083\n",
      "Epoch 106/500\n",
      " - 0s - loss: 2.7251 - accuracy: 0.2083\n",
      "Epoch 107/500\n",
      " - 0s - loss: 2.7151 - accuracy: 0.2083\n",
      "Epoch 108/500\n",
      " - 0s - loss: 2.7048 - accuracy: 0.2083\n",
      "Epoch 109/500\n",
      " - 0s - loss: 2.6944 - accuracy: 0.2083\n",
      "Epoch 110/500\n",
      " - 0s - loss: 2.6839 - accuracy: 0.2083\n",
      "Epoch 111/500\n",
      " - 0s - loss: 2.6732 - accuracy: 0.2083\n",
      "Epoch 112/500\n",
      " - 0s - loss: 2.6623 - accuracy: 0.2083\n",
      "Epoch 113/500\n",
      " - 0s - loss: 2.6513 - accuracy: 0.2083\n",
      "Epoch 114/500\n",
      " - 0s - loss: 2.6401 - accuracy: 0.2083\n",
      "Epoch 115/500\n",
      " - 0s - loss: 2.6287 - accuracy: 0.2083\n",
      "Epoch 116/500\n",
      " - 0s - loss: 2.6172 - accuracy: 0.2083\n",
      "Epoch 117/500\n",
      " - 0s - loss: 2.6056 - accuracy: 0.2083\n",
      "Epoch 118/500\n",
      " - 0s - loss: 2.5938 - accuracy: 0.2083\n",
      "Epoch 119/500\n",
      " - 0s - loss: 2.5819 - accuracy: 0.2083\n",
      "Epoch 120/500\n",
      " - 0s - loss: 2.5699 - accuracy: 0.2083\n",
      "Epoch 121/500\n",
      " - 0s - loss: 2.5577 - accuracy: 0.2083\n",
      "Epoch 122/500\n",
      " - 0s - loss: 2.5454 - accuracy: 0.2083\n",
      "Epoch 123/500\n",
      " - 0s - loss: 2.5330 - accuracy: 0.2083\n",
      "Epoch 124/500\n",
      " - 0s - loss: 2.5205 - accuracy: 0.2083\n",
      "Epoch 125/500\n",
      " - 0s - loss: 2.5079 - accuracy: 0.2083\n",
      "Epoch 126/500\n",
      " - 0s - loss: 2.4952 - accuracy: 0.2083\n",
      "Epoch 127/500\n",
      " - 0s - loss: 2.4824 - accuracy: 0.2083\n",
      "Epoch 128/500\n",
      " - 0s - loss: 2.4696 - accuracy: 0.2083\n",
      "Epoch 129/500\n",
      " - 0s - loss: 2.4567 - accuracy: 0.2083\n",
      "Epoch 130/500\n",
      " - 0s - loss: 2.4437 - accuracy: 0.2083\n",
      "Epoch 131/500\n",
      " - 0s - loss: 2.4307 - accuracy: 0.2083\n",
      "Epoch 132/500\n",
      " - 0s - loss: 2.4176 - accuracy: 0.2083\n",
      "Epoch 133/500\n",
      " - 0s - loss: 2.4045 - accuracy: 0.2083\n",
      "Epoch 134/500\n",
      " - 0s - loss: 2.3913 - accuracy: 0.2083\n",
      "Epoch 135/500\n",
      " - 0s - loss: 2.3781 - accuracy: 0.2083\n",
      "Epoch 136/500\n",
      " - 0s - loss: 2.3649 - accuracy: 0.2083\n",
      "Epoch 137/500\n",
      " - 0s - loss: 2.3516 - accuracy: 0.2083\n",
      "Epoch 138/500\n",
      " - 0s - loss: 2.3383 - accuracy: 0.2083\n",
      "Epoch 139/500\n",
      " - 0s - loss: 2.3251 - accuracy: 0.2083\n",
      "Epoch 140/500\n",
      " - 0s - loss: 2.3118 - accuracy: 0.2083\n",
      "Epoch 141/500\n",
      " - 0s - loss: 2.2985 - accuracy: 0.2083\n",
      "Epoch 142/500\n",
      " - 0s - loss: 2.2852 - accuracy: 0.2083\n",
      "Epoch 143/500\n",
      " - 0s - loss: 2.2719 - accuracy: 0.2083\n",
      "Epoch 144/500\n",
      " - 0s - loss: 2.2586 - accuracy: 0.2083\n",
      "Epoch 145/500\n",
      " - 0s - loss: 2.2453 - accuracy: 0.2083\n",
      "Epoch 146/500\n",
      " - 0s - loss: 2.2320 - accuracy: 0.2083\n",
      "Epoch 147/500\n",
      " - 0s - loss: 2.2187 - accuracy: 0.2083\n",
      "Epoch 148/500\n",
      " - 0s - loss: 2.2054 - accuracy: 0.2083\n",
      "Epoch 149/500\n",
      " - 0s - loss: 2.1922 - accuracy: 0.2500\n",
      "Epoch 150/500\n",
      " - 0s - loss: 2.1789 - accuracy: 0.2500\n",
      "Epoch 151/500\n",
      " - 0s - loss: 2.1657 - accuracy: 0.2917\n",
      "Epoch 152/500\n",
      " - 0s - loss: 2.1525 - accuracy: 0.2917\n",
      "Epoch 153/500\n",
      " - 0s - loss: 2.1392 - accuracy: 0.3333\n",
      "Epoch 154/500\n",
      " - 0s - loss: 2.1260 - accuracy: 0.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/500\n",
      " - 0s - loss: 2.1129 - accuracy: 0.3333\n",
      "Epoch 156/500\n",
      " - 0s - loss: 2.0997 - accuracy: 0.3333\n",
      "Epoch 157/500\n",
      " - 0s - loss: 2.0866 - accuracy: 0.3333\n",
      "Epoch 158/500\n",
      " - 0s - loss: 2.0735 - accuracy: 0.3333\n",
      "Epoch 159/500\n",
      " - 0s - loss: 2.0603 - accuracy: 0.3333\n",
      "Epoch 160/500\n",
      " - 0s - loss: 2.0472 - accuracy: 0.3750\n",
      "Epoch 161/500\n",
      " - 0s - loss: 2.0341 - accuracy: 0.3750\n",
      "Epoch 162/500\n",
      " - 0s - loss: 2.0210 - accuracy: 0.3750\n",
      "Epoch 163/500\n",
      " - 0s - loss: 2.0079 - accuracy: 0.3750\n",
      "Epoch 164/500\n",
      " - 0s - loss: 1.9947 - accuracy: 0.3750\n",
      "Epoch 165/500\n",
      " - 0s - loss: 1.9816 - accuracy: 0.4583\n",
      "Epoch 166/500\n",
      " - 0s - loss: 1.9685 - accuracy: 0.4583\n",
      "Epoch 167/500\n",
      " - 0s - loss: 1.9553 - accuracy: 0.4583\n",
      "Epoch 168/500\n",
      " - 0s - loss: 1.9422 - accuracy: 0.4583\n",
      "Epoch 169/500\n",
      " - 0s - loss: 1.9290 - accuracy: 0.5000\n",
      "Epoch 170/500\n",
      " - 0s - loss: 1.9159 - accuracy: 0.5000\n",
      "Epoch 171/500\n",
      " - 0s - loss: 1.9027 - accuracy: 0.5000\n",
      "Epoch 172/500\n",
      " - 0s - loss: 1.8895 - accuracy: 0.5000\n",
      "Epoch 173/500\n",
      " - 0s - loss: 1.8764 - accuracy: 0.5000\n",
      "Epoch 174/500\n",
      " - 0s - loss: 1.8632 - accuracy: 0.5000\n",
      "Epoch 175/500\n",
      " - 0s - loss: 1.8500 - accuracy: 0.5000\n",
      "Epoch 176/500\n",
      " - 0s - loss: 1.8367 - accuracy: 0.5000\n",
      "Epoch 177/500\n",
      " - 0s - loss: 1.8235 - accuracy: 0.5000\n",
      "Epoch 178/500\n",
      " - 0s - loss: 1.8103 - accuracy: 0.5000\n",
      "Epoch 179/500\n",
      " - 0s - loss: 1.7971 - accuracy: 0.5833\n",
      "Epoch 180/500\n",
      " - 0s - loss: 1.7838 - accuracy: 0.5833\n",
      "Epoch 181/500\n",
      " - 0s - loss: 1.7706 - accuracy: 0.6250\n",
      "Epoch 182/500\n",
      " - 0s - loss: 1.7573 - accuracy: 0.6250\n",
      "Epoch 183/500\n",
      " - 0s - loss: 1.7441 - accuracy: 0.6250\n",
      "Epoch 184/500\n",
      " - 0s - loss: 1.7308 - accuracy: 0.6250\n",
      "Epoch 185/500\n",
      " - 0s - loss: 1.7176 - accuracy: 0.6250\n",
      "Epoch 186/500\n",
      " - 0s - loss: 1.7043 - accuracy: 0.6250\n",
      "Epoch 187/500\n",
      " - 0s - loss: 1.6910 - accuracy: 0.6250\n",
      "Epoch 188/500\n",
      " - 0s - loss: 1.6777 - accuracy: 0.6250\n",
      "Epoch 189/500\n",
      " - 0s - loss: 1.6644 - accuracy: 0.6250\n",
      "Epoch 190/500\n",
      " - 0s - loss: 1.6511 - accuracy: 0.6250\n",
      "Epoch 191/500\n",
      " - 0s - loss: 1.6379 - accuracy: 0.6250\n",
      "Epoch 192/500\n",
      " - 0s - loss: 1.6246 - accuracy: 0.6250\n",
      "Epoch 193/500\n",
      " - 0s - loss: 1.6113 - accuracy: 0.6250\n",
      "Epoch 194/500\n",
      " - 0s - loss: 1.5981 - accuracy: 0.6250\n",
      "Epoch 195/500\n",
      " - 0s - loss: 1.5848 - accuracy: 0.6667\n",
      "Epoch 196/500\n",
      " - 0s - loss: 1.5716 - accuracy: 0.6667\n",
      "Epoch 197/500\n",
      " - 0s - loss: 1.5584 - accuracy: 0.6667\n",
      "Epoch 198/500\n",
      " - 0s - loss: 1.5452 - accuracy: 0.6667\n",
      "Epoch 199/500\n",
      " - 0s - loss: 1.5321 - accuracy: 0.6667\n",
      "Epoch 200/500\n",
      " - 0s - loss: 1.5190 - accuracy: 0.6667\n",
      "Epoch 201/500\n",
      " - 0s - loss: 1.5059 - accuracy: 0.7083\n",
      "Epoch 202/500\n",
      " - 0s - loss: 1.4929 - accuracy: 0.7083\n",
      "Epoch 203/500\n",
      " - 0s - loss: 1.4799 - accuracy: 0.7083\n",
      "Epoch 204/500\n",
      " - 0s - loss: 1.4669 - accuracy: 0.7083\n",
      "Epoch 205/500\n",
      " - 0s - loss: 1.4539 - accuracy: 0.7083\n",
      "Epoch 206/500\n",
      " - 0s - loss: 1.4411 - accuracy: 0.7083\n",
      "Epoch 207/500\n",
      " - 0s - loss: 1.4282 - accuracy: 0.7083\n",
      "Epoch 208/500\n",
      " - 0s - loss: 1.4154 - accuracy: 0.7083\n",
      "Epoch 209/500\n",
      " - 0s - loss: 1.4027 - accuracy: 0.7083\n",
      "Epoch 210/500\n",
      " - 0s - loss: 1.3900 - accuracy: 0.7083\n",
      "Epoch 211/500\n",
      " - 0s - loss: 1.3774 - accuracy: 0.7083\n",
      "Epoch 212/500\n",
      " - 0s - loss: 1.3648 - accuracy: 0.7083\n",
      "Epoch 213/500\n",
      " - 0s - loss: 1.3524 - accuracy: 0.7083\n",
      "Epoch 214/500\n",
      " - 0s - loss: 1.3399 - accuracy: 0.7500\n",
      "Epoch 215/500\n",
      " - 0s - loss: 1.3276 - accuracy: 0.7500\n",
      "Epoch 216/500\n",
      " - 0s - loss: 1.3153 - accuracy: 0.7500\n",
      "Epoch 217/500\n",
      " - 0s - loss: 1.3031 - accuracy: 0.7500\n",
      "Epoch 218/500\n",
      " - 0s - loss: 1.2910 - accuracy: 0.7500\n",
      "Epoch 219/500\n",
      " - 0s - loss: 1.2789 - accuracy: 0.7500\n",
      "Epoch 220/500\n",
      " - 0s - loss: 1.2669 - accuracy: 0.7500\n",
      "Epoch 221/500\n",
      " - 0s - loss: 1.2551 - accuracy: 0.7917\n",
      "Epoch 222/500\n",
      " - 0s - loss: 1.2433 - accuracy: 0.7917\n",
      "Epoch 223/500\n",
      " - 0s - loss: 1.2316 - accuracy: 0.7917\n",
      "Epoch 224/500\n",
      " - 0s - loss: 1.2199 - accuracy: 0.7917\n",
      "Epoch 225/500\n",
      " - 0s - loss: 1.2084 - accuracy: 0.7917\n",
      "Epoch 226/500\n",
      " - 0s - loss: 1.1970 - accuracy: 0.7917\n",
      "Epoch 227/500\n",
      " - 0s - loss: 1.1857 - accuracy: 0.7917\n",
      "Epoch 228/500\n",
      " - 0s - loss: 1.1744 - accuracy: 0.7917\n",
      "Epoch 229/500\n",
      " - 0s - loss: 1.1633 - accuracy: 0.7917\n",
      "Epoch 230/500\n",
      " - 0s - loss: 1.1522 - accuracy: 0.7917\n",
      "Epoch 231/500\n",
      " - 0s - loss: 1.1412 - accuracy: 0.7917\n",
      "Epoch 232/500\n",
      " - 0s - loss: 1.1304 - accuracy: 0.7917\n",
      "Epoch 233/500\n",
      " - 0s - loss: 1.1196 - accuracy: 0.7917\n",
      "Epoch 234/500\n",
      " - 0s - loss: 1.1090 - accuracy: 0.7917\n",
      "Epoch 235/500\n",
      " - 0s - loss: 1.0984 - accuracy: 0.8333\n",
      "Epoch 236/500\n",
      " - 0s - loss: 1.0880 - accuracy: 0.8333\n",
      "Epoch 237/500\n",
      " - 0s - loss: 1.0776 - accuracy: 0.8333\n",
      "Epoch 238/500\n",
      " - 0s - loss: 1.0674 - accuracy: 0.8333\n",
      "Epoch 239/500\n",
      " - 0s - loss: 1.0573 - accuracy: 0.8333\n",
      "Epoch 240/500\n",
      " - 0s - loss: 1.0473 - accuracy: 0.8333\n",
      "Epoch 241/500\n",
      " - 0s - loss: 1.0373 - accuracy: 0.8333\n",
      "Epoch 242/500\n",
      " - 0s - loss: 1.0275 - accuracy: 0.8333\n",
      "Epoch 243/500\n",
      " - 0s - loss: 1.0178 - accuracy: 0.8333\n",
      "Epoch 244/500\n",
      " - 0s - loss: 1.0083 - accuracy: 0.8333\n",
      "Epoch 245/500\n",
      " - 0s - loss: 0.9988 - accuracy: 0.8333\n",
      "Epoch 246/500\n",
      " - 0s - loss: 0.9894 - accuracy: 0.8333\n",
      "Epoch 247/500\n",
      " - 0s - loss: 0.9801 - accuracy: 0.8333\n",
      "Epoch 248/500\n",
      " - 0s - loss: 0.9709 - accuracy: 0.8333\n",
      "Epoch 249/500\n",
      " - 0s - loss: 0.9619 - accuracy: 0.8333\n",
      "Epoch 250/500\n",
      " - 0s - loss: 0.9529 - accuracy: 0.8333\n",
      "Epoch 251/500\n",
      " - 0s - loss: 0.9440 - accuracy: 0.8333\n",
      "Epoch 252/500\n",
      " - 0s - loss: 0.9353 - accuracy: 0.8333\n",
      "Epoch 253/500\n",
      " - 0s - loss: 0.9266 - accuracy: 0.8333\n",
      "Epoch 254/500\n",
      " - 0s - loss: 0.9181 - accuracy: 0.8333\n",
      "Epoch 255/500\n",
      " - 0s - loss: 0.9096 - accuracy: 0.8333\n",
      "Epoch 256/500\n",
      " - 0s - loss: 0.9013 - accuracy: 0.8333\n",
      "Epoch 257/500\n",
      " - 0s - loss: 0.8930 - accuracy: 0.8333\n",
      "Epoch 258/500\n",
      " - 0s - loss: 0.8849 - accuracy: 0.8333\n",
      "Epoch 259/500\n",
      " - 0s - loss: 0.8768 - accuracy: 0.8333\n",
      "Epoch 260/500\n",
      " - 0s - loss: 0.8689 - accuracy: 0.8333\n",
      "Epoch 261/500\n",
      " - 0s - loss: 0.8611 - accuracy: 0.8333\n",
      "Epoch 262/500\n",
      " - 0s - loss: 0.8533 - accuracy: 0.8333\n",
      "Epoch 263/500\n",
      " - 0s - loss: 0.8456 - accuracy: 0.8333\n",
      "Epoch 264/500\n",
      " - 0s - loss: 0.8381 - accuracy: 0.8333\n",
      "Epoch 265/500\n",
      " - 0s - loss: 0.8306 - accuracy: 0.8333\n",
      "Epoch 266/500\n",
      " - 0s - loss: 0.8232 - accuracy: 0.8333\n",
      "Epoch 267/500\n",
      " - 0s - loss: 0.8160 - accuracy: 0.8333\n",
      "Epoch 268/500\n",
      " - 0s - loss: 0.8088 - accuracy: 0.8333\n",
      "Epoch 269/500\n",
      " - 0s - loss: 0.8017 - accuracy: 0.8333\n",
      "Epoch 270/500\n",
      " - 0s - loss: 0.7947 - accuracy: 0.8333\n",
      "Epoch 271/500\n",
      " - 0s - loss: 0.7878 - accuracy: 0.8333\n",
      "Epoch 272/500\n",
      " - 0s - loss: 0.7809 - accuracy: 0.8333\n",
      "Epoch 273/500\n",
      " - 0s - loss: 0.7742 - accuracy: 0.8333\n",
      "Epoch 274/500\n",
      " - 0s - loss: 0.7675 - accuracy: 0.8333\n",
      "Epoch 275/500\n",
      " - 0s - loss: 0.7610 - accuracy: 0.8333\n",
      "Epoch 276/500\n",
      " - 0s - loss: 0.7545 - accuracy: 0.8333\n",
      "Epoch 277/500\n",
      " - 0s - loss: 0.7481 - accuracy: 0.8333\n",
      "Epoch 278/500\n",
      " - 0s - loss: 0.7418 - accuracy: 0.8333\n",
      "Epoch 279/500\n",
      " - 0s - loss: 0.7356 - accuracy: 0.8333\n",
      "Epoch 280/500\n",
      " - 0s - loss: 0.7294 - accuracy: 0.8333\n",
      "Epoch 281/500\n",
      " - 0s - loss: 0.7233 - accuracy: 0.8333\n",
      "Epoch 282/500\n",
      " - 0s - loss: 0.7173 - accuracy: 0.8333\n",
      "Epoch 283/500\n",
      " - 0s - loss: 0.7114 - accuracy: 0.8333\n",
      "Epoch 284/500\n",
      " - 0s - loss: 0.7056 - accuracy: 0.8333\n",
      "Epoch 285/500\n",
      " - 0s - loss: 0.6998 - accuracy: 0.8333\n",
      "Epoch 286/500\n",
      " - 0s - loss: 0.6941 - accuracy: 0.8333\n",
      "Epoch 287/500\n",
      " - 0s - loss: 0.6884 - accuracy: 0.8333\n",
      "Epoch 288/500\n",
      " - 0s - loss: 0.6829 - accuracy: 0.8333\n",
      "Epoch 289/500\n",
      " - 0s - loss: 0.6774 - accuracy: 0.8333\n",
      "Epoch 290/500\n",
      " - 0s - loss: 0.6720 - accuracy: 0.8333\n",
      "Epoch 291/500\n",
      " - 0s - loss: 0.6666 - accuracy: 0.8333\n",
      "Epoch 292/500\n",
      " - 0s - loss: 0.6613 - accuracy: 0.8333\n",
      "Epoch 293/500\n",
      " - 0s - loss: 0.6561 - accuracy: 0.8333\n",
      "Epoch 294/500\n",
      " - 0s - loss: 0.6509 - accuracy: 0.8333\n",
      "Epoch 295/500\n",
      " - 0s - loss: 0.6458 - accuracy: 0.8333\n",
      "Epoch 296/500\n",
      " - 0s - loss: 0.6408 - accuracy: 0.8333\n",
      "Epoch 297/500\n",
      " - 0s - loss: 0.6358 - accuracy: 0.8333\n",
      "Epoch 298/500\n",
      " - 0s - loss: 0.6309 - accuracy: 0.8333\n",
      "Epoch 299/500\n",
      " - 0s - loss: 0.6260 - accuracy: 0.8333\n",
      "Epoch 300/500\n",
      " - 0s - loss: 0.6212 - accuracy: 0.8333\n",
      "Epoch 301/500\n",
      " - 0s - loss: 0.6165 - accuracy: 0.8333\n",
      "Epoch 302/500\n",
      " - 0s - loss: 0.6118 - accuracy: 0.8333\n",
      "Epoch 303/500\n",
      " - 0s - loss: 0.6071 - accuracy: 0.8333\n",
      "Epoch 304/500\n",
      " - 0s - loss: 0.6025 - accuracy: 0.8333\n",
      "Epoch 305/500\n",
      " - 0s - loss: 0.5980 - accuracy: 0.8333\n",
      "Epoch 306/500\n",
      " - 0s - loss: 0.5935 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 307/500\n",
      " - 0s - loss: 0.5891 - accuracy: 0.8333\n",
      "Epoch 308/500\n",
      " - 0s - loss: 0.5847 - accuracy: 0.8333\n",
      "Epoch 309/500\n",
      " - 0s - loss: 0.5804 - accuracy: 0.8333\n",
      "Epoch 310/500\n",
      " - 0s - loss: 0.5761 - accuracy: 0.8333\n",
      "Epoch 311/500\n",
      " - 0s - loss: 0.5719 - accuracy: 0.8333\n",
      "Epoch 312/500\n",
      " - 0s - loss: 0.5677 - accuracy: 0.8333\n",
      "Epoch 313/500\n",
      " - 0s - loss: 0.5635 - accuracy: 0.8333\n",
      "Epoch 314/500\n",
      " - 0s - loss: 0.5594 - accuracy: 0.8333\n",
      "Epoch 315/500\n",
      " - 0s - loss: 0.5554 - accuracy: 0.8333\n",
      "Epoch 316/500\n",
      " - 0s - loss: 0.5514 - accuracy: 0.8333\n",
      "Epoch 317/500\n",
      " - 0s - loss: 0.5475 - accuracy: 0.8333\n",
      "Epoch 318/500\n",
      " - 0s - loss: 0.5436 - accuracy: 0.8333\n",
      "Epoch 319/500\n",
      " - 0s - loss: 0.5397 - accuracy: 0.8333\n",
      "Epoch 320/500\n",
      " - 0s - loss: 0.5359 - accuracy: 0.8333\n",
      "Epoch 321/500\n",
      " - 0s - loss: 0.5321 - accuracy: 0.8333\n",
      "Epoch 322/500\n",
      " - 0s - loss: 0.5284 - accuracy: 0.8333\n",
      "Epoch 323/500\n",
      " - 0s - loss: 0.5247 - accuracy: 0.8333\n",
      "Epoch 324/500\n",
      " - 0s - loss: 0.5210 - accuracy: 0.8333\n",
      "Epoch 325/500\n",
      " - 0s - loss: 0.5174 - accuracy: 0.8333\n",
      "Epoch 326/500\n",
      " - 0s - loss: 0.5138 - accuracy: 0.8750\n",
      "Epoch 327/500\n",
      " - 0s - loss: 0.5103 - accuracy: 0.8750\n",
      "Epoch 328/500\n",
      " - 0s - loss: 0.5068 - accuracy: 0.8750\n",
      "Epoch 329/500\n",
      " - 0s - loss: 0.5033 - accuracy: 0.8750\n",
      "Epoch 330/500\n",
      " - 0s - loss: 0.4999 - accuracy: 0.8750\n",
      "Epoch 331/500\n",
      " - 0s - loss: 0.4965 - accuracy: 0.8750\n",
      "Epoch 332/500\n",
      " - 0s - loss: 0.4932 - accuracy: 0.8750\n",
      "Epoch 333/500\n",
      " - 0s - loss: 0.4899 - accuracy: 0.8750\n",
      "Epoch 334/500\n",
      " - 0s - loss: 0.4867 - accuracy: 0.8750\n",
      "Epoch 335/500\n",
      " - 0s - loss: 0.4834 - accuracy: 0.8750\n",
      "Epoch 336/500\n",
      " - 0s - loss: 0.4803 - accuracy: 0.8750\n",
      "Epoch 337/500\n",
      " - 0s - loss: 0.4771 - accuracy: 0.8750\n",
      "Epoch 338/500\n",
      " - 0s - loss: 0.4740 - accuracy: 0.8750\n",
      "Epoch 339/500\n",
      " - 0s - loss: 0.4709 - accuracy: 0.8750\n",
      "Epoch 340/500\n",
      " - 0s - loss: 0.4679 - accuracy: 0.8750\n",
      "Epoch 341/500\n",
      " - 0s - loss: 0.4649 - accuracy: 0.8750\n",
      "Epoch 342/500\n",
      " - 0s - loss: 0.4619 - accuracy: 0.8750\n",
      "Epoch 343/500\n",
      " - 0s - loss: 0.4590 - accuracy: 0.8750\n",
      "Epoch 344/500\n",
      " - 0s - loss: 0.4561 - accuracy: 0.8750\n",
      "Epoch 345/500\n",
      " - 0s - loss: 0.4532 - accuracy: 0.8750\n",
      "Epoch 346/500\n",
      " - 0s - loss: 0.4504 - accuracy: 0.8750\n",
      "Epoch 347/500\n",
      " - 0s - loss: 0.4476 - accuracy: 0.8750\n",
      "Epoch 348/500\n",
      " - 0s - loss: 0.4448 - accuracy: 0.8750\n",
      "Epoch 349/500\n",
      " - 0s - loss: 0.4421 - accuracy: 0.8750\n",
      "Epoch 350/500\n",
      " - 0s - loss: 0.4394 - accuracy: 0.8750\n",
      "Epoch 351/500\n",
      " - 0s - loss: 0.4367 - accuracy: 0.8750\n",
      "Epoch 352/500\n",
      " - 0s - loss: 0.4341 - accuracy: 0.8750\n",
      "Epoch 353/500\n",
      " - 0s - loss: 0.4315 - accuracy: 0.8750\n",
      "Epoch 354/500\n",
      " - 0s - loss: 0.4290 - accuracy: 0.8750\n",
      "Epoch 355/500\n",
      " - 0s - loss: 0.4264 - accuracy: 0.8750\n",
      "Epoch 356/500\n",
      " - 0s - loss: 0.4239 - accuracy: 0.8750\n",
      "Epoch 357/500\n",
      " - 0s - loss: 0.4215 - accuracy: 0.8750\n",
      "Epoch 358/500\n",
      " - 0s - loss: 0.4190 - accuracy: 0.8750\n",
      "Epoch 359/500\n",
      " - 0s - loss: 0.4166 - accuracy: 0.8750\n",
      "Epoch 360/500\n",
      " - 0s - loss: 0.4142 - accuracy: 0.8750\n",
      "Epoch 361/500\n",
      " - 0s - loss: 0.4119 - accuracy: 0.8750\n",
      "Epoch 362/500\n",
      " - 0s - loss: 0.4096 - accuracy: 0.8750\n",
      "Epoch 363/500\n",
      " - 0s - loss: 0.4073 - accuracy: 0.8750\n",
      "Epoch 364/500\n",
      " - 0s - loss: 0.4051 - accuracy: 0.8750\n",
      "Epoch 365/500\n",
      " - 0s - loss: 0.4028 - accuracy: 0.8750\n",
      "Epoch 366/500\n",
      " - 0s - loss: 0.4006 - accuracy: 0.8750\n",
      "Epoch 367/500\n",
      " - 0s - loss: 0.3985 - accuracy: 0.8750\n",
      "Epoch 368/500\n",
      " - 0s - loss: 0.3963 - accuracy: 0.8750\n",
      "Epoch 369/500\n",
      " - 0s - loss: 0.3942 - accuracy: 0.8750\n",
      "Epoch 370/500\n",
      " - 0s - loss: 0.3921 - accuracy: 0.8750\n",
      "Epoch 371/500\n",
      " - 0s - loss: 0.3901 - accuracy: 0.8750\n",
      "Epoch 372/500\n",
      " - 0s - loss: 0.3881 - accuracy: 0.8750\n",
      "Epoch 373/500\n",
      " - 0s - loss: 0.3861 - accuracy: 0.8750\n",
      "Epoch 374/500\n",
      " - 0s - loss: 0.3841 - accuracy: 0.8750\n",
      "Epoch 375/500\n",
      " - 0s - loss: 0.3822 - accuracy: 0.8750\n",
      "Epoch 376/500\n",
      " - 0s - loss: 0.3802 - accuracy: 0.8750\n",
      "Epoch 377/500\n",
      " - 0s - loss: 0.3783 - accuracy: 0.8750\n",
      "Epoch 378/500\n",
      " - 0s - loss: 0.3765 - accuracy: 0.8750\n",
      "Epoch 379/500\n",
      " - 0s - loss: 0.3746 - accuracy: 0.8750\n",
      "Epoch 380/500\n",
      " - 0s - loss: 0.3728 - accuracy: 0.8750\n",
      "Epoch 381/500\n",
      " - 0s - loss: 0.3710 - accuracy: 0.8750\n",
      "Epoch 382/500\n",
      " - 0s - loss: 0.3693 - accuracy: 0.8750\n",
      "Epoch 383/500\n",
      " - 0s - loss: 0.3675 - accuracy: 0.8750\n",
      "Epoch 384/500\n",
      " - 0s - loss: 0.3658 - accuracy: 0.8750\n",
      "Epoch 385/500\n",
      " - 0s - loss: 0.3641 - accuracy: 0.8750\n",
      "Epoch 386/500\n",
      " - 0s - loss: 0.3624 - accuracy: 0.8750\n",
      "Epoch 387/500\n",
      " - 0s - loss: 0.3608 - accuracy: 0.8750\n",
      "Epoch 388/500\n",
      " - 0s - loss: 0.3591 - accuracy: 0.8750\n",
      "Epoch 389/500\n",
      " - 0s - loss: 0.3575 - accuracy: 0.8750\n",
      "Epoch 390/500\n",
      " - 0s - loss: 0.3560 - accuracy: 0.8750\n",
      "Epoch 391/500\n",
      " - 0s - loss: 0.3544 - accuracy: 0.8750\n",
      "Epoch 392/500\n",
      " - 0s - loss: 0.3529 - accuracy: 0.8750\n",
      "Epoch 393/500\n",
      " - 0s - loss: 0.3513 - accuracy: 0.8750\n",
      "Epoch 394/500\n",
      " - 0s - loss: 0.3498 - accuracy: 0.8750\n",
      "Epoch 395/500\n",
      " - 0s - loss: 0.3484 - accuracy: 0.8750\n",
      "Epoch 396/500\n",
      " - 0s - loss: 0.3469 - accuracy: 0.8750\n",
      "Epoch 397/500\n",
      " - 0s - loss: 0.3455 - accuracy: 0.8750\n",
      "Epoch 398/500\n",
      " - 0s - loss: 0.3440 - accuracy: 0.8750\n",
      "Epoch 399/500\n",
      " - 0s - loss: 0.3426 - accuracy: 0.8750\n",
      "Epoch 400/500\n",
      " - 0s - loss: 0.3413 - accuracy: 0.8750\n",
      "Epoch 401/500\n",
      " - 0s - loss: 0.3399 - accuracy: 0.8750\n",
      "Epoch 402/500\n",
      " - 0s - loss: 0.3386 - accuracy: 0.8750\n",
      "Epoch 403/500\n",
      " - 0s - loss: 0.3372 - accuracy: 0.8750\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.3359 - accuracy: 0.8750\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.3346 - accuracy: 0.8750\n",
      "Epoch 406/500\n",
      " - 0s - loss: 0.3334 - accuracy: 0.8750\n",
      "Epoch 407/500\n",
      " - 0s - loss: 0.3321 - accuracy: 0.8750\n",
      "Epoch 408/500\n",
      " - 0s - loss: 0.3309 - accuracy: 0.8750\n",
      "Epoch 409/500\n",
      " - 0s - loss: 0.3296 - accuracy: 0.8750\n",
      "Epoch 410/500\n",
      " - 0s - loss: 0.3284 - accuracy: 0.8750\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.3272 - accuracy: 0.8750\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.3261 - accuracy: 0.8750\n",
      "Epoch 413/500\n",
      " - 0s - loss: 0.3249 - accuracy: 0.8750\n",
      "Epoch 414/500\n",
      " - 0s - loss: 0.3238 - accuracy: 0.8750\n",
      "Epoch 415/500\n",
      " - 0s - loss: 0.3226 - accuracy: 0.8750\n",
      "Epoch 416/500\n",
      " - 0s - loss: 0.3215 - accuracy: 0.8750\n",
      "Epoch 417/500\n",
      " - 0s - loss: 0.3204 - accuracy: 0.8750\n",
      "Epoch 418/500\n",
      " - 0s - loss: 0.3193 - accuracy: 0.8750\n",
      "Epoch 419/500\n",
      " - 0s - loss: 0.3182 - accuracy: 0.8750\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.3172 - accuracy: 0.8750\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.3161 - accuracy: 0.8750\n",
      "Epoch 422/500\n",
      " - 0s - loss: 0.3151 - accuracy: 0.8750\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.3141 - accuracy: 0.8750\n",
      "Epoch 424/500\n",
      " - 0s - loss: 0.3131 - accuracy: 0.8750\n",
      "Epoch 425/500\n",
      " - 0s - loss: 0.3121 - accuracy: 0.8750\n",
      "Epoch 426/500\n",
      " - 0s - loss: 0.3111 - accuracy: 0.8750\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.3101 - accuracy: 0.8750\n",
      "Epoch 428/500\n",
      " - 0s - loss: 0.3092 - accuracy: 0.8750\n",
      "Epoch 429/500\n",
      " - 0s - loss: 0.3082 - accuracy: 0.8750\n",
      "Epoch 430/500\n",
      " - 0s - loss: 0.3073 - accuracy: 0.8750\n",
      "Epoch 431/500\n",
      " - 0s - loss: 0.3063 - accuracy: 0.8750\n",
      "Epoch 432/500\n",
      " - 0s - loss: 0.3054 - accuracy: 0.8750\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.3045 - accuracy: 0.8750\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.3036 - accuracy: 0.8750\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.3027 - accuracy: 0.8750\n",
      "Epoch 436/500\n",
      " - 0s - loss: 0.3019 - accuracy: 0.8750\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.3010 - accuracy: 0.8750\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.3001 - accuracy: 0.8750\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.2993 - accuracy: 0.8750\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.2984 - accuracy: 0.8750\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.2976 - accuracy: 0.8750\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.2968 - accuracy: 0.8750\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.2960 - accuracy: 0.8750\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.2952 - accuracy: 0.8750\n",
      "Epoch 445/500\n",
      " - 0s - loss: 0.2944 - accuracy: 0.8750\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.2936 - accuracy: 0.8750\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.2928 - accuracy: 0.8750\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.2920 - accuracy: 0.8750\n",
      "Epoch 449/500\n",
      " - 0s - loss: 0.2913 - accuracy: 0.8750\n",
      "Epoch 450/500\n",
      " - 0s - loss: 0.2905 - accuracy: 0.8750\n",
      "Epoch 451/500\n",
      " - 0s - loss: 0.2898 - accuracy: 0.8750\n",
      "Epoch 452/500\n",
      " - 0s - loss: 0.2890 - accuracy: 0.8750\n",
      "Epoch 453/500\n",
      " - 0s - loss: 0.2883 - accuracy: 0.8750\n",
      "Epoch 454/500\n",
      " - 0s - loss: 0.2876 - accuracy: 0.8750\n",
      "Epoch 455/500\n",
      " - 0s - loss: 0.2868 - accuracy: 0.8750\n",
      "Epoch 456/500\n",
      " - 0s - loss: 0.2861 - accuracy: 0.8750\n",
      "Epoch 457/500\n",
      " - 0s - loss: 0.2854 - accuracy: 0.8750\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.2847 - accuracy: 0.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 459/500\n",
      " - 0s - loss: 0.2840 - accuracy: 0.8750\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.2833 - accuracy: 0.8750\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.2827 - accuracy: 0.8750\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.2820 - accuracy: 0.8750\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.2813 - accuracy: 0.8750\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.2806 - accuracy: 0.8750\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.2800 - accuracy: 0.8750\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.2793 - accuracy: 0.8750\n",
      "Epoch 467/500\n",
      " - 0s - loss: 0.2787 - accuracy: 0.8750\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.2780 - accuracy: 0.8750\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.2774 - accuracy: 0.8750\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.2768 - accuracy: 0.8750\n",
      "Epoch 471/500\n",
      " - 0s - loss: 0.2761 - accuracy: 0.8750\n",
      "Epoch 472/500\n",
      " - 0s - loss: 0.2755 - accuracy: 0.8750\n",
      "Epoch 473/500\n",
      " - 0s - loss: 0.2749 - accuracy: 0.8750\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.2743 - accuracy: 0.8750\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.2737 - accuracy: 0.8750\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.2731 - accuracy: 0.8750\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.2725 - accuracy: 0.8750\n",
      "Epoch 478/500\n",
      " - 0s - loss: 0.2719 - accuracy: 0.8750\n",
      "Epoch 479/500\n",
      " - 0s - loss: 0.2713 - accuracy: 0.8750\n",
      "Epoch 480/500\n",
      " - 0s - loss: 0.2707 - accuracy: 0.8750\n",
      "Epoch 481/500\n",
      " - 0s - loss: 0.2701 - accuracy: 0.8750\n",
      "Epoch 482/500\n",
      " - 0s - loss: 0.2695 - accuracy: 0.8750\n",
      "Epoch 483/500\n",
      " - 0s - loss: 0.2690 - accuracy: 0.8750\n",
      "Epoch 484/500\n",
      " - 0s - loss: 0.2684 - accuracy: 0.8750\n",
      "Epoch 485/500\n",
      " - 0s - loss: 0.2678 - accuracy: 0.8750\n",
      "Epoch 486/500\n",
      " - 0s - loss: 0.2673 - accuracy: 0.8750\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.2667 - accuracy: 0.8750\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.2662 - accuracy: 0.8750\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.2656 - accuracy: 0.8750\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.2651 - accuracy: 0.8750\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.2645 - accuracy: 0.8750\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.2640 - accuracy: 0.8750\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.2634 - accuracy: 0.8750\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.2629 - accuracy: 0.8750\n",
      "Epoch 495/500\n",
      " - 0s - loss: 0.2624 - accuracy: 0.8750\n",
      "Epoch 496/500\n",
      " - 0s - loss: 0.2618 - accuracy: 0.8750\n",
      "Epoch 497/500\n",
      " - 0s - loss: 0.2613 - accuracy: 0.8750\n",
      "Epoch 498/500\n",
      " - 0s - loss: 0.2608 - accuracy: 0.8750\n",
      "Epoch 499/500\n",
      " - 0s - loss: 0.2603 - accuracy: 0.8750\n",
      "Epoch 500/500\n",
      " - 0s - loss: 0.2598 - accuracy: 0.8750\n",
      "Jack and jill came tumbling after jack\n"
     ]
    }
   ],
   "source": [
    "# generate a sequence from the model\n",
    "def generate_seq(model, tokenizer, seed_text, n_words):\n",
    "    in_text, result = seed_text, seed_text\n",
    "    # generate a fixed number of words\n",
    "    for _ in range(n_words):\n",
    "        # encode the text as integer\n",
    "        encoded = tokenizer.texts_to_sequences([in_text])[0]\n",
    "        encoded = array(encoded)\n",
    "        # predict a word in the vocabulary\n",
    "        yhat = model.predict_classes(encoded, verbose=0)\n",
    "        # map predicted word index to word\n",
    "        out_word = ''\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == yhat:\n",
    "                out_word = word\n",
    "                break\n",
    "        # append to input\n",
    "        in_text, result = out_word, result + ' ' + out_word\n",
    "    return result\n",
    "\n",
    "# source text\n",
    "data = \"\"\" Jack and Jill went up the hill\\n\n",
    "        To fetch a pail of water\\n\n",
    "        Jack fell down and broke his crown\\n\n",
    "        And Jill came tumbling after\\n \"\"\"\n",
    "\n",
    "# integer encode text\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])\n",
    "encoded = tokenizer.texts_to_sequences([data])[0]\n",
    "\n",
    "\n",
    "# determine the vocabulary size\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print('Vocabulary Size: %d' % vocab_size)\n",
    "\n",
    "# create word -> word sequences\n",
    "sequences = list()\n",
    "for i in range(1, len(encoded)):\n",
    "\tsequence = encoded[i-1:i+1]\n",
    "\tsequences.append(sequence)\n",
    "print('Total Sequences: %d' % len(sequences))\n",
    "\n",
    "# split into X and y elements\n",
    "sequences = array(sequences)\n",
    "X, y = sequences[:,0],sequences[:,1]\n",
    "\n",
    "# one hot encode outputs\n",
    "y = to_categorical(y, num_classes=vocab_size)\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "# compile network\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit network\n",
    "model.fit(X, y, epochs=500, verbose=2)\n",
    "\n",
    "# evaluate\n",
    "print(generate_seq(model, tokenizer, 'Jack', 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
